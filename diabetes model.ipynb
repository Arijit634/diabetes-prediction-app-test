{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.8441558441558441\n",
      "F1 Score: 0.8459448714550755\n",
      "Precision: 0.850370147247935\n",
      "Recall: 0.8441558441558441\n",
      "Confusion Matrix:\n",
      " [[86 15]\n",
      " [ 9 44]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"diabetes - DS.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "df_copy = df.copy(deep=True)\n",
    "df_copy[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df_copy[\n",
    "    ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.NaN)\n",
    "df_copy['Glucose'].fillna(df_copy['Glucose'].mean(), inplace=True)\n",
    "df_copy['BloodPressure'].fillna(df_copy['BloodPressure'].mean(), inplace=True)\n",
    "df_copy['SkinThickness'].fillna(df_copy['SkinThickness'].median(), inplace=True)\n",
    "df_copy['Insulin'].fillna(df_copy['Insulin'].median(), inplace=True)\n",
    "df_copy['BMI'].fillna(df_copy['BMI'].median(), inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df_copy.drop(columns=['Outcome'])\n",
    "y = df_copy['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=194)\n",
    "\n",
    "# Convert X_test back to a DataFrame \n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Combine X_test_df and y_test into a single DataFrame\n",
    "test_df = pd.concat([X_test_df, y_test], axis=1)\n",
    "\n",
    "# Export only the test set to CSV\n",
    "test_df.to_csv(\"preprocessed_test_dataset.csv\", index=False)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler using pickle\n",
    "with open('standard_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "# Remove outliers using z-score\n",
    "z_scores = zscore(X_train)\n",
    "threshold = 3\n",
    "X_train_no_outliers = X_train[(np.abs(z_scores) < threshold).all(axis=1)]\n",
    "y_train_no_outliers = y_train[(np.abs(z_scores) < threshold).all(axis=1)]\n",
    "\n",
    "# Use RandomOverSampler to handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = ros.fit_resample(X_train_no_outliers, y_train_no_outliers)\n",
    "\n",
    "# Concatenate X_test and y_test and convert to DataFrame\n",
    "test_data = pd.concat([pd.DataFrame(X_test, columns=X.columns), pd.DataFrame(y_test, columns=['Outcome'])], axis=1)\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "df_copy.to_csv('preprocessed_data.csv', index=False)\n",
    "\n",
    "class GradientBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators=300, learning_rate=0.1, max_depth=2):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        residuals = np.copy(y).astype(float)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            self.models.append(tree)\n",
    "\n",
    "            predictions = tree.predict(X)\n",
    "            residuals -= self.learning_rate * predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.models:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return (predictions > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        sum_predictions = np.zeros(len(X))\n",
    "        for tree in self.models:\n",
    "            sum_predictions += self.learning_rate * tree.predict(X)\n",
    "\n",
    "        proba_positive_class = 1 / (1 + np.exp(-sum_predictions))\n",
    "        proba_negative_class = 1 - proba_positive_class\n",
    "\n",
    "        return np.column_stack((proba_negative_class, proba_positive_class))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "class CustomKNN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        return Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for x in X:\n",
    "            distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            class_counts = Counter(k_nearest_labels)\n",
    "            prob_class_0 = class_counts[0] / self.k\n",
    "            prob_class_1 = class_counts[1] / self.k\n",
    "            probabilities.append([prob_class_0, prob_class_1])\n",
    "        return np.array(probabilities)\n",
    "\n",
    "class CustomVotingClassifier:\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        if weights is None:\n",
    "            self.weights = [1/len(models)] * len(models)  \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_pred_val = model.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val, y_pred_val)\n",
    "            self.weights[i] = accuracy\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        weighted_votes = np.average(predictions, axis=0, weights=self.weights)\n",
    "        return (weighted_votes > 0.5).astype(int)\n",
    "\n",
    "# Create instances of CustomKNN and GradientBoostingClassifier\n",
    "knn_model = CustomKNN()\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Create the CustomVotingClassifier with CustomKNN and GradientBoostingClassifier\n",
    "voting_clf = CustomVotingClassifier(models=[knn_model, gb_model])\n",
    "\n",
    "# Fit the VotingClassifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the VotingClassifier\n",
    "voting_preds_train = voting_clf.predict(X_train)\n",
    "voting_preds_test = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy_test = accuracy_score(y_test, voting_preds_test)\n",
    "\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)\n",
    "\n",
    "# Calculate F1 score, precision, recall, and confusion matrix\n",
    "f1 = f1_score(y_test, voting_preds_test, average='weighted')\n",
    "precision = precision_score(y_test, voting_preds_test, average='weighted')\n",
    "recall = recall_score(y_test, voting_preds_test, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, voting_preds_test)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Save the model using pickle\n",
    "with open('hybrid_model.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
